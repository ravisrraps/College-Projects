{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a27b83bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mouth_aspect_ratio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12044/1891865631.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# Average the mouth aspect ratio together for both eyes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[0mmar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmouth_aspect_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmouth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m     \u001b[0mleftEAR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meye_aspect_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleftEye\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mrightEAR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meye_aspect_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrightEye\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mouth_aspect_ratio' is not defined"
     ]
    }
   ],
   "source": [
    "from imutils import face_utils\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import pyautogui as pag\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "# Thresholds and consecutive frame length for triggering the mouse action.\n",
    "MOUTH_AR_THRESH = 0.6\n",
    "MOUTH_AR_CONSECUTIVE_FRAMES = 15\n",
    "EYE_AR_THRESH = 0.19\n",
    "EYE_AR_CONSECUTIVE_FRAMES = 15\n",
    "WINK_AR_DIFF_THRESH = 0.04\n",
    "WINK_AR_CLOSE_THRESH = 0.19\n",
    "WINK_CONSECUTIVE_FRAMES = 10\n",
    "\n",
    "# Initialize the frame counters for each action as well as \n",
    "# booleans used to indicate if action is performed or not\n",
    "MOUTH_COUNTER = 0\n",
    "EYE_COUNTER = 0\n",
    "WINK_COUNTER = 0\n",
    "INPUT_MODE = False\n",
    "EYE_CLICK = False\n",
    "LEFT_WINK = False\n",
    "RIGHT_WINK = False\n",
    "SCROLL_MODE = False\n",
    "ANCHOR_POINT = (0, 0)\n",
    "WHITE_COLOR = (255, 255, 255)\n",
    "YELLOW_COLOR = (0, 255, 255)\n",
    "RED_COLOR = (0, 0, 255)\n",
    "GREEN_COLOR = (0, 255, 0)\n",
    "BLUE_COLOR = (255, 0, 0)\n",
    "BLACK_COLOR = (0, 0, 0)\n",
    "\n",
    "# Initialize Dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "shape_predictor = \"model/shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(shape_predictor)\n",
    "\n",
    "# Grab the indexes of the facial landmarks for the left and\n",
    "# right eye, nose and mouth respectively\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "(nStart, nEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"nose\"]\n",
    "(mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "\n",
    "# Video capture\n",
    "vid = cv2.VideoCapture(0)\n",
    "resolution_w = 1366\n",
    "resolution_h = 768\n",
    "cam_w = 640\n",
    "cam_h = 480\n",
    "unit_w = resolution_w / cam_w\n",
    "unit_h = resolution_h / cam_h\n",
    "\n",
    "while True:\n",
    "    # Grab the frame from the threaded video file stream, resize\n",
    "    # it, and convert it to grayscale\n",
    "    # channels)\n",
    "    _, frame = vid.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = imutils.resize(frame, width=cam_w, height=cam_h)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    # Loop over the face detections\n",
    "    if len(rects) > 0:\n",
    "        rect = rects[0]\n",
    "    else:\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        continue\n",
    "\n",
    "    # Determine the facial landmarks for the face region, then\n",
    "    # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "    # array\n",
    "    shape = predictor(gray, rect)\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "    # Extract the left and right eye coordinates, then use the\n",
    "    # coordinates to compute the eye aspect ratio for both eyes\n",
    "    mouth = shape[mStart:mEnd]\n",
    "    leftEye = shape[lStart:lEnd]\n",
    "    rightEye = shape[rStart:rEnd]\n",
    "    nose = shape[nStart:nEnd]\n",
    "\n",
    "    # Because I flipped the frame, left is right, right is left.\n",
    "    temp = leftEye\n",
    "    leftEye = rightEye\n",
    "    rightEye = temp\n",
    "\n",
    "    # Average the mouth aspect ratio together for both eyes\n",
    "    mar = mouth_aspect_ratio(mouth)\n",
    "    leftEAR = eye_aspect_ratio(leftEye)\n",
    "    rightEAR = eye_aspect_ratio(rightEye)\n",
    "    ear = (leftEAR + rightEAR) / 2.0\n",
    "    diff_ear = np.abs(leftEAR - rightEAR)\n",
    "\n",
    "    nose_point = (nose[3, 0], nose[3, 1])\n",
    "\n",
    "    # Compute the convex hull for the left and right eye, then\n",
    "    # visualize each of the eyes\n",
    "    mouthHull = cv2.convexHull(mouth)\n",
    "    leftEyeHull = cv2.convexHull(leftEye)\n",
    "    rightEyeHull = cv2.convexHull(rightEye)\n",
    "    cv2.drawContours(frame, [mouthHull], -1, YELLOW_COLOR, 1)\n",
    "    cv2.drawContours(frame, [leftEyeHull], -1, YELLOW_COLOR, 1)\n",
    "    cv2.drawContours(frame, [rightEyeHull], -1, YELLOW_COLOR, 1)\n",
    "\n",
    "    for (x, y) in np.concatenate((mouth, leftEye, rightEye), axis=0):\n",
    "        cv2.circle(frame, (x, y), 2, GREEN_COLOR, -1)\n",
    "        \n",
    "    # Check to see if the eye aspect ratio is below the blink\n",
    "    # threshold, and if so, increment the blink frame counter\n",
    "    if diff_ear > WINK_AR_DIFF_THRESH:\n",
    "\n",
    "        if leftEAR < rightEAR:\n",
    "            if leftEAR < EYE_AR_THRESH:\n",
    "                WINK_COUNTER += 1\n",
    "\n",
    "                if WINK_COUNTER > WINK_CONSECUTIVE_FRAMES:\n",
    "                    pag.click(button='left')\n",
    "\n",
    "                    WINK_COUNTER = 0\n",
    "\n",
    "        elif leftEAR > rightEAR:\n",
    "            if rightEAR < EYE_AR_THRESH:\n",
    "                WINK_COUNTER += 1\n",
    "\n",
    "                if WINK_COUNTER > WINK_CONSECUTIVE_FRAMES:\n",
    "                    pag.click(button='right')\n",
    "\n",
    "                    WINK_COUNTER = 0\n",
    "        else:\n",
    "            WINK_COUNTER = 0\n",
    "    else:\n",
    "        if ear <= EYE_AR_THRESH:\n",
    "            EYE_COUNTER += 1\n",
    "\n",
    "            if EYE_COUNTER > EYE_AR_CONSECUTIVE_FRAMES:\n",
    "                SCROLL_MODE = not SCROLL_MODE\n",
    "                # INPUT_MODE = not INPUT_MODE\n",
    "                EYE_COUNTER = 0\n",
    "\n",
    "                # nose point to draw a bounding box around it\n",
    "\n",
    "        else:\n",
    "            EYE_COUNTER = 0\n",
    "            WINK_COUNTER = 0\n",
    "\n",
    "    if mar > MOUTH_AR_THRESH:\n",
    "        MOUTH_COUNTER += 1\n",
    "\n",
    "        if MOUTH_COUNTER >= MOUTH_AR_CONSECUTIVE_FRAMES:\n",
    "            # if the alarm is not on, turn it on\n",
    "            INPUT_MODE = not INPUT_MODE\n",
    "            # SCROLL_MODE = not SCROLL_MODE\n",
    "            MOUTH_COUNTER = 0\n",
    "            ANCHOR_POINT = nose_point\n",
    "\n",
    "    else:\n",
    "        MOUTH_COUNTER = 0\n",
    "\n",
    "    if INPUT_MODE:\n",
    "        cv2.putText(frame, \"READING INPUT!\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, RED_COLOR, 2)\n",
    "        x, y = ANCHOR_POINT\n",
    "        nx, ny = nose_point\n",
    "        w, h = 60, 35\n",
    "        multiple = 1\n",
    "        cv2.rectangle(frame, (x - w, y - h), (x + w, y + h), GREEN_COLOR, 2)\n",
    "        cv2.line(frame, ANCHOR_POINT, nose_point, BLUE_COLOR, 2)\n",
    "\n",
    "        dir = direction(nose_point, ANCHOR_POINT, w, h)\n",
    "        cv2.putText(frame, dir.upper(), (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, RED_COLOR, 2)\n",
    "        drag = 18\n",
    "        if dir == 'right':\n",
    "            pag.moveRel(drag, 0)\n",
    "        elif dir == 'left':\n",
    "            pag.moveRel(-drag, 0)\n",
    "        elif dir == 'up':\n",
    "            if SCROLL_MODE:\n",
    "                pag.scroll(40)\n",
    "            else:\n",
    "                pag.moveRel(0, -drag)\n",
    "        elif dir == 'down':\n",
    "            if SCROLL_MODE:\n",
    "                pag.scroll(-40)\n",
    "            else:\n",
    "                pag.moveRel(0, drag)\n",
    "\n",
    "    if SCROLL_MODE:\n",
    "        cv2.putText(frame, 'SCROLL MODE IS ON!', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, RED_COLOR, 2)\n",
    "\n",
    "    # cv2.putText(frame, \"MAR: {:.2f}\".format(mar), (500, 30),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, YELLOW_COLOR, 2)\n",
    "    # cv2.putText(frame, \"Right EAR: {:.2f}\".format(rightEAR), (460, 80),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, YELLOW_COLOR, 2)\n",
    "    # cv2.putText(frame, \"Left EAR: {:.2f}\".format(leftEAR), (460, 130),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, YELLOW_COLOR, 2)\n",
    "    # cv2.putText(frame, \"Diff EARaa: {:.2f}\".format(np.abs(leftEAR - rightEAR)), (460, 80),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # If the `Esc` key was pressed, break from the loop\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "# Do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "319e84fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mouth_aspect_ratio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12044/2864749908.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# Average the mouth aspect ratio together for both eyes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[0mmar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmouth_aspect_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmouth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m     \u001b[0mleftEAR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meye_aspect_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleftEye\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mrightEAR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meye_aspect_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrightEye\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mouth_aspect_ratio' is not defined"
     ]
    }
   ],
   "source": [
    "from imutils import face_utils\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import pyautogui as pag\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "# Thresholds and consecutive frame length for triggering the mouse action.\n",
    "MOUTH_AR_THRESH = 0.6\n",
    "MOUTH_AR_CONSECUTIVE_FRAMES = 15\n",
    "EYE_AR_THRESH = 0.19\n",
    "EYE_AR_CONSECUTIVE_FRAMES = 15\n",
    "WINK_AR_DIFF_THRESH = 0.04\n",
    "WINK_AR_CLOSE_THRESH = 0.19\n",
    "WINK_CONSECUTIVE_FRAMES = 10\n",
    "\n",
    "# Initialize the frame counters for each action as well as \n",
    "# booleans used to indicate if action is performed or not\n",
    "MOUTH_COUNTER = 0\n",
    "EYE_COUNTER = 0\n",
    "WINK_COUNTER = 0\n",
    "INPUT_MODE = False\n",
    "EYE_CLICK = False\n",
    "LEFT_WINK = False\n",
    "RIGHT_WINK = False\n",
    "SCROLL_MODE = False\n",
    "ANCHOR_POINT = (0, 0)\n",
    "WHITE_COLOR = (255, 255, 255)\n",
    "YELLOW_COLOR = (0, 255, 255)\n",
    "RED_COLOR = (0, 0, 255)\n",
    "GREEN_COLOR = (0, 255, 0)\n",
    "BLUE_COLOR = (255, 0, 0)\n",
    "BLACK_COLOR = (0, 0, 0)\n",
    "\n",
    "# Initialize Dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "shape_predictor = \"model/shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(shape_predictor)\n",
    "\n",
    "# Grab the indexes of the facial landmarks for the left and\n",
    "# right eye, nose and mouth respectively\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "(nStart, nEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"nose\"]\n",
    "(mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "\n",
    "# Video capture\n",
    "vid = cv2.VideoCapture(0)\n",
    "resolution_w = 1366\n",
    "resolution_h = 768\n",
    "cam_w = 640\n",
    "cam_h = 480\n",
    "unit_w = resolution_w / cam_w\n",
    "unit_h = resolution_h / cam_h\n",
    "\n",
    "while True:\n",
    "    # Grab the frame from the threaded video file stream, resize\n",
    "    # it, and convert it to grayscale\n",
    "    # channels)\n",
    "    _, frame = vid.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = imutils.resize(frame, width=cam_w, height=cam_h)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    # Loop over the face detections\n",
    "    if len(rects) > 0:\n",
    "        rect = rects[0]\n",
    "    else:\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        continue\n",
    "\n",
    "    # Determine the facial landmarks for the face region, then\n",
    "    # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "    # array\n",
    "    shape = predictor(gray, rect)\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "    # Extract the left and right eye coordinates, then use the\n",
    "    # coordinates to compute the eye aspect ratio for both eyes\n",
    "    mouth = shape[mStart:mEnd]\n",
    "    leftEye = shape[lStart:lEnd]\n",
    "    rightEye = shape[rStart:rEnd]\n",
    "    nose = shape[nStart:nEnd]\n",
    "\n",
    "    # Because I flipped the frame, left is right, right is left.\n",
    "    temp = leftEye\n",
    "    leftEye = rightEye\n",
    "    rightEye = temp\n",
    "\n",
    "    # Average the mouth aspect ratio together for both eyes\n",
    "    mar = mouth_aspect_ratio(mouth)\n",
    "    leftEAR = eye_aspect_ratio(leftEye)\n",
    "    rightEAR = eye_aspect_ratio(rightEye)\n",
    "    ear = (leftEAR + rightEAR) / 2.0\n",
    "    diff_ear = np.abs(leftEAR - rightEAR)\n",
    "\n",
    "    nose_point = (nose[3, 0], nose[3, 1])\n",
    "\n",
    "    # Compute the convex hull for the left and right eye, then\n",
    "    # visualize each of the eyes\n",
    "    mouthHull = cv2.convexHull(mouth)\n",
    "    leftEyeHull = cv2.convexHull(leftEye)\n",
    "    rightEyeHull = cv2.convexHull(rightEye)\n",
    "    cv2.drawContours(frame, [mouthHull], -1, YELLOW_COLOR, 1)\n",
    "    cv2.drawContours(frame, [leftEyeHull], -1, YELLOW_COLOR, 1)\n",
    "    cv2.drawContours(frame, [rightEyeHull], -1, YELLOW_COLOR, 1)\n",
    "\n",
    "    for (x, y) in np.concatenate((mouth, leftEye, rightEye), axis=0):\n",
    "        cv2.circle(frame, (x, y), 2, GREEN_COLOR, -1)\n",
    "        \n",
    "    # Check to see if the eye aspect ratio is below the blink\n",
    "    # threshold, and if so, increment the blink frame counter\n",
    "    if diff_ear > WINK_AR_DIFF_THRESH:\n",
    "\n",
    "        if leftEAR < rightEAR:\n",
    "            if leftEAR < EYE_AR_THRESH:\n",
    "                WINK_COUNTER += 1\n",
    "\n",
    "                if WINK_COUNTER > WINK_CONSECUTIVE_FRAMES:\n",
    "                    pag.click(button='left')\n",
    "\n",
    "                    WINK_COUNTER = 0\n",
    "\n",
    "        elif leftEAR > rightEAR:\n",
    "            if rightEAR < EYE_AR_THRESH:\n",
    "                WINK_COUNTER += 1\n",
    "\n",
    "                if WINK_COUNTER > WINK_CONSECUTIVE_FRAMES:\n",
    "                    pag.click(button='right')\n",
    "\n",
    "                    WINK_COUNTER = 0\n",
    "        else:\n",
    "            WINK_COUNTER = 0\n",
    "    else:\n",
    "        if ear <= EYE_AR_THRESH:\n",
    "            EYE_COUNTER += 1\n",
    "\n",
    "            if EYE_COUNTER > EYE_AR_CONSECUTIVE_FRAMES:\n",
    "                SCROLL_MODE = not SCROLL_MODE\n",
    "                # INPUT_MODE = not INPUT_MODE\n",
    "                EYE_COUNTER = 0\n",
    "\n",
    "                # nose point to draw a bounding box around it\n",
    "\n",
    "        else:\n",
    "            EYE_COUNTER = 0\n",
    "            WINK_COUNTER = 0\n",
    "\n",
    "    if mar > MOUTH_AR_THRESH:\n",
    "        MOUTH_COUNTER += 1\n",
    "\n",
    "        if MOUTH_COUNTER >= MOUTH_AR_CONSECUTIVE_FRAMES:\n",
    "            # if the alarm is not on, turn it on\n",
    "            INPUT_MODE = not INPUT_MODE\n",
    "            # SCROLL_MODE = not SCROLL_MODE\n",
    "            MOUTH_COUNTER = 0\n",
    "            ANCHOR_POINT = nose_point\n",
    "\n",
    "    else:\n",
    "        MOUTH_COUNTER = 0\n",
    "\n",
    "    if INPUT_MODE:\n",
    "        cv2.putText(frame, \"READING INPUT!\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, RED_COLOR, 2)\n",
    "        x, y = ANCHOR_POINT\n",
    "        nx, ny = nose_point\n",
    "        w, h = 60, 35\n",
    "        multiple = 1\n",
    "        cv2.rectangle(frame, (x - w, y - h), (x + w, y + h), GREEN_COLOR, 2)\n",
    "        cv2.line(frame, ANCHOR_POINT, nose_point, BLUE_COLOR, 2)\n",
    "\n",
    "        dir = direction(nose_point, ANCHOR_POINT, w, h)\n",
    "        cv2.putText(frame, dir.upper(), (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, RED_COLOR, 2)\n",
    "        drag = 18\n",
    "        if dir == 'right':\n",
    "            pag.moveRel(drag, 0)\n",
    "        elif dir == 'left':\n",
    "            pag.moveRel(-drag, 0)\n",
    "        elif dir == 'up':\n",
    "            if SCROLL_MODE:\n",
    "                pag.scroll(40)\n",
    "            else:\n",
    "                pag.moveRel(0, -drag)\n",
    "        elif dir == 'down':\n",
    "            if SCROLL_MODE:\n",
    "                pag.scroll(-40)\n",
    "            else:\n",
    "                pag.moveRel(0, drag)\n",
    "\n",
    "    if SCROLL_MODE:\n",
    "        cv2.putText(frame, 'SCROLL MODE IS ON!', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, RED_COLOR, 2)\n",
    "\n",
    "    # cv2.putText(frame, \"MAR: {:.2f}\".format(mar), (500, 30),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, YELLOW_COLOR, 2)\n",
    "    # cv2.putText(frame, \"Right EAR: {:.2f}\".format(rightEAR), (460, 80),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, YELLOW_COLOR, 2)\n",
    "    # cv2.putText(frame, \"Left EAR: {:.2f}\".format(leftEAR), (460, 130),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, YELLOW_COLOR, 2)\n",
    "    # cv2.putText(frame, \"Diff EAR: {:.2f}\".format(np.abs(leftEAR - rightEAR)), (460, 80),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # If the `Esc` key was pressed, break from the loop\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "# Do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99abd294-f470-49f3-ad20-348f26c17689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
